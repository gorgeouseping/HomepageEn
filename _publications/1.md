---
title: "Semantic segmentation of 3D indoor LiDAR point clouds through feature pyramid architecture search"
collection: publications
permalink: /publication/1
excerpt: "H Lin, S Wu, Y Chen *, W Li, Z Luo, C Wang, J Li * <br/>ISPRS Journal of Photogrammetry and Remote Sensing, October, 2021<br/><img src=\"/images/SemanticSegmentationOf.jpg\">" #'H Lin, S Wu, Y Chen*, W Li, Z Luo, C Wang, J Li* <br/>ISPRS Journal of Photogrammetry and Remote Sensing, October, 2021<br/><img src='https://gorgeouseping.github.io/HomepageCh/images/SemanticSegmentationOf.jpg'>'
date: 2021-10-01
venue: ''
paperurl: 'https://gorgeouseping.github.io/HomepageCh/files/SemanticSegmentationOf.pdf'
---
## Abstract
Semantic segmentation of 3D Light Detection and Ranging (LiDAR) indoor point clouds using deep learning has been an active topic in recent years. However, most deep neural networks on point clouds conduct multi-level feature fusion via a simple U-shape architecture, which lacks enough capacity on both classification and localization in the segmentation task. In this paper, we propose a Neural Architecture Search (NAS) method to search a Feature Pyramid Network (FPN) module for 3D indoor point cloud semantic segmentation. Specifically, we aim to automatically find an effective feature pyramid architecture as a feature fusion neck in a designed novel pyramidal search space covering all information communication paths for multi-level features. The searched FPN module, named SFPN, contains the most important connections among all the potential paths to fuse representations at different levels. Our proposed SFPN is generic and effective as well as capable to be added to existing segmentation networks to augment the segmentation performance. Extensive experiments on ScanNet and S3DIS show that consistent and remarkable gains of segmentation performance can be achieved by different classical networks combined with SFPN. Specially, PointNet++-SFPN achieves mIoU gains of 7.8% on ScanNet v2 and 4.7% on S3DIS, and PointConv-SFPN achieves 4.5% and 3.7% improvement respectively on the above datasets.

[Full text](https://doi.org/10.1016/j.isprsjprs.2021.05.009)
